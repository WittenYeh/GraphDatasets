# download_datasets.py

import os
import requests
import gzip
import shutil
from tqdm.auto import tqdm

# --- è¦ä¸‹è½½çš„æ•°æ®é›†URLåˆ—è¡¨ ---
DATASET_URLS = [
    "https://snap.stanford.edu/data/bigdata/communities/com-dblp.ungraph.txt.gz",
    "https://snap.stanford.edu/data/bigdata/communities/com-lj.ungraph.txt.gz",
    "https://snap.stanford.edu/data/bigdata/communities/com-orkut.ungraph.txt.gz",
    "https://snap.stanford.edu/data/bigdata/communities/com-friendster.ungraph.txt.gz",
    "https://snap.stanford.edu/data/cit-Patents.txt.gz",
    "https://snap.stanford.edu/data/twitter-2010.txt.gz",
]

def download_and_extract(url: str):
    """
    ä»ç»™å®šçš„URLä¸‹è½½æ–‡ä»¶ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
    - æ£€æŸ¥æœ€ç»ˆæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡ã€‚
    - æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚
    - æ˜¾ç¤ºä¸‹è½½å’Œè§£å‹çš„è¿›åº¦æ¡ã€‚
    - æˆåŠŸè§£å‹åè‡ªåŠ¨åˆ é™¤.gzå‹ç¼©åŒ…ã€‚
    """
    # 1. ä»URLæ´¾ç”Ÿæ–‡ä»¶å
    gz_filename = os.path.basename(url)
    txt_filename = gz_filename[:-3]  # ç§»é™¤.gzåç¼€

    # --- æ£€æŸ¥1: å¦‚æœæœ€ç»ˆè§£å‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™å®Œå…¨è·³è¿‡ ---
    if os.path.exists(txt_filename):
        print(f"âœ… '{txt_filename}' å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
        return

    print(f"\nProcessing: {gz_filename}")
    
    # 2. å‡†å¤‡ä¸‹è½½ï¼Œå®ç°æ–­ç‚¹ç»­ä¼ 
    local_size = 0
    # å¦‚æœå‹ç¼©æ–‡ä»¶å·²å­˜åœ¨ï¼ˆä½†æœªå®Œå…¨ä¸‹è½½ï¼‰ï¼Œè·å–å…¶å¤§å°
    if os.path.exists(gz_filename):
        local_size = os.path.getsize(gz_filename)

    try:
        # ä½¿ç”¨HEADè¯·æ±‚é¢„å…ˆè·å–æ–‡ä»¶æ€»å¤§å°ï¼Œé¿å…ä¸‹è½½
        head_response = requests.head(url, allow_redirects=True, timeout=10)
        head_response.raise_for_status()
        total_size = int(head_response.headers.get('content-length', 0))

        # --- æ£€æŸ¥2: å¦‚æœå‹ç¼©æ–‡ä»¶å·²å®Œæ•´ä¸‹è½½ï¼Œåˆ™è·³è¿‡ä¸‹è½½æ­¥éª¤ ---
        if local_size >= total_size > 0:
            print(f"ğŸ“¦ '{gz_filename}' å·²å®Œæ•´ä¸‹è½½ï¼Œå‡†å¤‡è§£å‹ã€‚")
        else:
            # 3. æ‰§è¡Œä¸‹è½½
            print(f"Downloading '{gz_filename}'...")
            # è®¾ç½®HTTPå¤´ï¼Œè¯·æ±‚ä»ä¸Šæ¬¡ä¸­æ–­çš„ä½ç½®å¼€å§‹ä¸‹è½½
            headers = {'Range': f'bytes={local_size}-'}
            
            with requests.get(url, stream=True, headers=headers, timeout=30) as r:
                # å¦‚æœæœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ (è¿”å›200)ï¼Œåˆ™ä»å¤´å¼€å§‹ä¸‹è½½
                mode = 'ab' if r.status_code == 206 else 'wb'
                if mode == 'ab':
                    print(f"Resuming download from {local_size / 1024**2:.2f} MB...")
                
                r.raise_for_status()
                
                with open(gz_filename, mode) as f, tqdm(
                    desc=gz_filename,
                    initial=local_size,
                    total=total_size,
                    unit='B',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as pbar:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))

    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½ '{url}' æ—¶å‡ºé”™: {e}")
        return

    # 4. è§£å‹æ–‡ä»¶
    print(f"Decompressing '{gz_filename}'...")
    try:
        # è·å–å‹ç¼©æ–‡ä»¶çš„å¤§å°ï¼Œç”¨äºè§£å‹è¿›åº¦æ¡
        compressed_size = os.path.getsize(gz_filename)
        with gzip.open(gz_filename, 'rb') as f_in:
            with open(txt_filename, 'wb') as f_out, tqdm(
                desc=f"Extracting",
                total=compressed_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                # ä¸ºäº†åœ¨å¤åˆ¶æ—¶æ›´æ–°è¿›åº¦æ¡ï¼Œæˆ‘ä»¬åˆ†å—è¯»å–å’Œå†™å…¥
                while True:
                    chunk = f_in.read(8192)
                    if not chunk:
                        break
                    f_out.write(chunk)
                    pbar.update(len(chunk))

        # 5. æ¸…ç†ä¸‹è½½çš„å‹ç¼©åŒ…
        print(f"âœ… è§£å‹æˆåŠŸ. åˆ é™¤ '{gz_filename}'.")
        os.remove(gz_filename)

    except (gzip.BadGzipFile, EOFError) as e:
        print(f"âŒ è§£å‹ '{gz_filename}' å‡ºé”™: {e}. æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´ï¼Œè¯·é‡æ–°è¿è¡Œè„šæœ¬ã€‚")
    except Exception as e:
        print(f"âŒ è§£å‹è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")


def main():
    """
    è„šæœ¬ä¸»å‡½æ•°ï¼Œéå†æ‰€æœ‰URLå¹¶æ‰§è¡Œä¸‹è½½è§£å‹ä»»åŠ¡ã€‚
    """
    print("--- å¼€å§‹ä¸‹è½½å¹¶å¤„ç†SNAPæ•°æ®é›† ---")
    for url in DATASET_URLS:
        download_and_extract(url)
    print("\n--- æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ ---")


if __name__ == "__main__":
    main()